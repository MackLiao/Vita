server.port=8080

# Demo configuration
#langchain4j.open-ai.chat-model.base-url=http://langchain4j.dev/demo/openai/v1
#langchain4j.open-ai.chat-model.api-key=demo

# OpenAI configuration
langchain4j.open-ai.chat-model.api-key=${OPENAI_API_KEY}
langchain4j.open-ai.chat-model.model-name=gpt-5-mini

# Ollama configuration
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=gemma3:270m
langchain4j.ollama.chat-model.temperature=0
langchain4j.ollama.chat-model.timeout=PT60S

# Dashscope configuration
langchain4j.community.dashscope.chat-model.api-Key=${DASH_SCOPE_API_KEY}
langchain4j.community.dashscope.chat-model.model-name=qwen-max

# Streaming chatmodel
langchain4j.community.dashscope.streaming-chat-model.api-Key=${DASH_SCOPE_API_KEY}
langchain4j.community.dashscope.streaming-chat-model.model-name=qwen-plus

# LLM call logs and response logs
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true

# MongoDB connection configs
spring.data.mongodb.uri=mongodb://localhost:27017/chat_memory_db

# mysql connection configs
spring.datasource.url=jdbc:mysql://localhost:3306/vita?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai&useSSL=false
spring.datasource.username=root
spring.datasource.password=12345678
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
mybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl

# Vector model config
langchain4j.community.dashscope.embedding-model.api-key=${DASH_SCOPE_API_KEY}
langchain4j.community.dashscope.embedding-model.model-name=text-embedding-v3

# Root level debugging
logging.level.root=info